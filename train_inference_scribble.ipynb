{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4604fb38",
   "metadata": {},
   "source": [
    "### Author:   __Snehit__\n",
    "### E-mail:   *snehitc@gmail.com*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef78475",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e433755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import utils.utils as utils\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from datasets.fetch_data import get_dataset, get_infdataset\n",
    "from evaluate import evaluate_all\n",
    "from features.all_feature_dict import get_all_features_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451cbff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./m2d/')\n",
    "sys.path.append('./MGA-CLAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ade4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = \"config_submission4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "296569ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = utils.load_config(config_filename)\n",
    "cfg['config_filename'] = config_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e182fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\n",
    "                    cfg[\"train_list\"],\n",
    "                    os.path.join(cfg[\"wav_dir\"], \"train\"),\n",
    "                    max_sec=cfg[\"max_len\"],\n",
    "                    sr=cfg[\"sample_rate\"],\n",
    "                    org_max=10.0,\n",
    "                    org_min=0.0\n",
    "                    )\n",
    "val_ds   = get_dataset(\n",
    "                    cfg[\"validation_list\"],\n",
    "                    os.path.join(cfg[\"wav_dir\"], \"validation\"),\n",
    "                    max_sec=cfg[\"max_len\"],\n",
    "                    sr=cfg[\"sample_rate\"],\n",
    "                    org_max=10.0,\n",
    "                    org_min=0.0\n",
    "                    )\n",
    "train_loader = DataLoader(\n",
    "                    train_ds,\n",
    "                    batch_size=cfg[\"batch_size\"],\n",
    "                    shuffle=False,\n",
    "                    num_workers=cfg[\"num_workers\"],\n",
    "                    collate_fn=train_ds.collate_fn,\n",
    "                    drop_last=False\n",
    "                    )\n",
    "val_loader = DataLoader(\n",
    "                    val_ds, \n",
    "                    batch_size=cfg[\"validation_batch_size\"], \n",
    "                    shuffle=False,\n",
    "                    num_workers=cfg[\"num_workers\"], \n",
    "                    collate_fn=val_ds.collate_fn\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "391add5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds   = get_infdataset(\n",
    "                    cfg[\"test_list\"],\n",
    "                    os.path.join(cfg[\"wav_dir\"], \"test\"),\n",
    "                    max_sec=cfg[\"max_len\"],\n",
    "                    sr=cfg[\"sample_rate\"],\n",
    "                    )\n",
    "test_loader = DataLoader(\n",
    "                    test_ds, \n",
    "                    batch_size=cfg[\"test_batch_size\"], \n",
    "                    shuffle=False,\n",
    "                    num_workers=cfg[\"num_workers\"], \n",
    "                    collate_fn=test_ds.collate_fn\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd44884",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0bec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetLabels(label_dict):\n",
    "    for i, (key, value) in enumerate(label_dict.items()):\n",
    "        if i!=0:\n",
    "            if not np.array_equal(value, value_previous):\n",
    "                raise ValueError(\"different labels for same data point \\nRecommended to set dataloaders with shuffle=False\")\n",
    "        value_previous = value\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "\n",
    "def Fit_SVR(Ensemble_set, X_comb, X_comb_val, y, y_val, SVR_input_param, cfg):\n",
    "    # Preprocessing\n",
    "    print('Preprocessing...')\n",
    "    Normalizer_ = Normalizer().fit(X_comb)  # fit does nothing.\n",
    "    X_scaled_comb = Normalizer_.transform(X_comb)\n",
    "    X_scaled_comb_val = Normalizer_.transform(X_comb_val)\n",
    "\n",
    "    StandardScaler_ = StandardScaler()\n",
    "    X_scaled_comb = StandardScaler_.fit_transform(X_scaled_comb)\n",
    "    X_scaled_comb_val = StandardScaler_.transform(X_scaled_comb_val)\n",
    "\n",
    "\n",
    "    # SVR_A\n",
    "    print('Training SVR...')\n",
    "    SVR_ = SVR(C=SVR_input_param['C'], \n",
    "                kernel=SVR_input_param['kernel'], \n",
    "                epsilon=SVR_input_param['epsilon'], \n",
    "                gamma=SVR_input_param['gamma'])\n",
    "    SVR_.fit(X_scaled_comb, y)\n",
    "\n",
    "    # Train and Validation Results\n",
    "    print('Predicting on Train set...')\n",
    "    y_pred_train = SVR_.predict(X_scaled_comb)\n",
    "    y_pred_train_denorm = y_pred_train*5 + 5\n",
    "    y_denorm = y*5 + 5\n",
    "    results = evaluate_all(y_pred_train_denorm, y_denorm)\n",
    "    print('\\t', results)\n",
    "\n",
    "    print('Predicting on Val set...')\n",
    "    y_pred_val = SVR_.predict(X_scaled_comb_val)\n",
    "    y_pred_val_denorm = y_pred_val*5 + 5\n",
    "    y_val_denorm = y_val*5 + 5\n",
    "    results_val = evaluate_all(y_pred_val_denorm, y_val_denorm)\n",
    "    print('\\t', results_val)\n",
    "\n",
    "    # Save the trained SVR and Preprocessor\n",
    "    utils.Save_Preprocessor_and_SVR(Normalizer_, StandardScaler_, SVR_, Ensemble_set, cfg)\n",
    "\n",
    "    params = SVR_.dual_coef_.size + SVR_.intercept_.size\n",
    "    return y_pred_train_denorm, y_pred_val_denorm, params\n",
    "\n",
    "\n",
    "\n",
    "def Fit_SVR_A(X_dict, X_dict_val, y_dict, y_dict_val, SVR_input_param, param, cfg): \n",
    "        Ensemble_set = 'A'\n",
    "        print(f'--- SVR {Ensemble_set} ---')\n",
    "        X_comb_A = np.concatenate((X_dict['M2D_Clap']['AudioFeatures'], X_dict['M2D_Clap']['TextFeatures'], X_dict['M2D_Clap']['Cosine_Sim'], \n",
    "                            X_dict['M2D_Clap']['Cosine_Ang'], X_dict['M2D_Clap']['L2'], X_dict['M2D_Clap']['L1'],\n",
    "\n",
    "                            X_dict['MS_Clap']['AudioFeatures'], X_dict['MS_Clap']['TextFeatures'], X_dict['MS_Clap']['Cosine_Sim'], \n",
    "                            X_dict['MS_Clap']['Cosine_Ang'], X_dict['MS_Clap']['L2'], X_dict['MS_Clap']['L1'],\n",
    "                             \n",
    "                            X_dict['MGA_Clap']['AudioFeatures'], X_dict['MGA_Clap']['TextFeatures'], X_dict['MGA_Clap']['Cosine_Sim'], \n",
    "                            X_dict['MGA_Clap']['Cosine_Ang'], X_dict['MGA_Clap']['L2'], X_dict['MGA_Clap']['L1'],), axis=1)\n",
    "\n",
    "        X_comb_val_A = np.concatenate((X_dict_val['M2D_Clap']['AudioFeatures'], X_dict_val['M2D_Clap']['TextFeatures'], X_dict_val['M2D_Clap']['Cosine_Sim'], \n",
    "                                    X_dict_val['M2D_Clap']['Cosine_Ang'], X_dict_val['M2D_Clap']['L2'], X_dict_val['M2D_Clap']['L1'],\n",
    "\n",
    "                                    X_dict_val['MS_Clap']['AudioFeatures'], X_dict_val['MS_Clap']['TextFeatures'], X_dict_val['MS_Clap']['Cosine_Sim'], \n",
    "                                    X_dict_val['MS_Clap']['Cosine_Ang'], X_dict_val['MS_Clap']['L2'], X_dict_val['MS_Clap']['L1'],\n",
    "                                    \n",
    "                                    X_dict_val['MGA_Clap']['AudioFeatures'], X_dict_val['MGA_Clap']['TextFeatures'], X_dict_val['MGA_Clap']['Cosine_Sim'], \n",
    "                                    X_dict_val['MGA_Clap']['Cosine_Ang'], X_dict_val['MGA_Clap']['L2'], X_dict_val['MGA_Clap']['L1'],), axis=1)\n",
    "        \n",
    "        y = GetLabels(y_dict)\n",
    "        y_val = GetLabels(y_dict_val)\n",
    "        y_pred_train_denorm_A, y_pred_val_denorm_A, params = Fit_SVR(Ensemble_set, X_comb_A, X_comb_val_A, y, y_val, \n",
    "                                                                     SVR_input_param, cfg)\n",
    "        param['SVR_'+Ensemble_set] = params\n",
    "        return y_pred_train_denorm_A, y_pred_val_denorm_A, param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Fit_SVR_B(X_dict, X_dict_val, y_dict, y_dict_val, SVR_input_param, param, cfg):\n",
    "        Ensemble_set = 'B'\n",
    "        print(f'\\n--- SVR {Ensemble_set} ---')\n",
    "        X_comb_B = np.concatenate((X_dict['Laion_Clap']['AudioFeatures'], X_dict['Laion_Clap']['TextFeatures'], X_dict['Laion_Clap']['L1'], \n",
    "                               X_dict['Whisper']['AudioFeatures'], X_dict['Whisper']['TextFeatures'],), axis=1)\n",
    "\n",
    "        X_comb_val_B = np.concatenate((X_dict_val['Laion_Clap']['AudioFeatures'], X_dict_val['Laion_Clap']['TextFeatures'], X_dict_val['Laion_Clap']['L1'],\n",
    "                                   X_dict_val['Whisper']['AudioFeatures'], X_dict_val['Whisper']['TextFeatures'],), axis=1)\n",
    "        \n",
    "        y = GetLabels(y_dict)\n",
    "        y_val = GetLabels(y_dict_val)\n",
    "        y_pred_train_denorm_B, y_pred_val_denorm_B, params = Fit_SVR(Ensemble_set, X_comb_B, X_comb_val_B, y, y_val, \n",
    "                                                                SVR_input_param, cfg)\n",
    "        param['SVR_'+Ensemble_set] = params\n",
    "        return y_pred_train_denorm_B, y_pred_val_denorm_B, param\n",
    "\n",
    "\n",
    "\n",
    "def Param_count(param):\n",
    "        count = 0\n",
    "        for key, val in param.items():\n",
    "            count += val\n",
    "        print(f'\\nTotal Parameter Count: {count}')\n",
    "\n",
    "\n",
    "def RMSE(y, y_pred):\n",
    "    rsme = np.sqrt(np.mean( (y-y_pred)**2) )\n",
    "    return rsme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "731dc11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train set ------\n",
      "*** [1/5]Extracting features using M2D_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u5049807/miniconda3/envs/xacle_exp_env/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " using 166 parameters from m2d/m2d_clap_vit_base-80x1001p16x16p16kpBpTI-2025/checkpoint-30.pth\n",
      " (included audio_proj params: ['audio_proj.sem_token', 'audio_proj.sem_blocks.0.norm1.weight', 'audio_proj.sem_blocks.0.norm1.bias', 'audio_proj.sem_blocks.0.attn.qkv.weight', 'audio_proj.sem_blocks.0.attn.qkv.bias']\n",
      " (included text_proj params: []\n",
      " (dropped: [] )\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " using model.text_encoder from ./m2d/m2d_clap_vit_base-80x1001p16x16p16kpBpTI-2025/checkpoint-30.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [03:37<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [1/5]Finished Extracting features using M2D_Clap ***\n",
      "\n",
      "*** [2/5]Extracting features using MS_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [01:28<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [2/5]Finished Extracting features using MS_Clap ***\n",
      "\n",
      "*** [3/5]Extracting features using Laion_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [02:43<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [3/5]Finished Extracting features using Laion_Clap ***\n",
      "\n",
      "*** [4/5]Extracting features using MGA_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:38<00:00, 24.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [4/5]Finished Extracting features using MGA_Clap ***\n",
      "\n",
      "*** [5/5]Extracting features using Whisper... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [27:26<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [5/5]Finished Extracting features using Whisper ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------ Train set ------\")\n",
    "if 'X_dict' not in globals() and 'y_dict' not in globals() and 'param' not in globals():\n",
    "    X_dict, y_dict, param = get_all_features_in_dict(train_loader, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0c1734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Val set ------\n",
      "*** [1/5]Extracting features using M2D_Clap... ***\n",
      " using 166 parameters from m2d/m2d_clap_vit_base-80x1001p16x16p16kpBpTI-2025/checkpoint-30.pth\n",
      " (included audio_proj params: ['audio_proj.sem_token', 'audio_proj.sem_blocks.0.norm1.weight', 'audio_proj.sem_blocks.0.norm1.bias', 'audio_proj.sem_blocks.0.attn.qkv.weight', 'audio_proj.sem_blocks.0.attn.qkv.bias']\n",
      " (included text_proj params: []\n",
      " (dropped: [] )\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " using model.text_encoder from ./m2d/m2d_clap_vit_base-80x1001p16x16p16kpBpTI-2025/checkpoint-30.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:04<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [1/5]Finished Extracting features using M2D_Clap ***\n",
      "\n",
      "*** [2/5]Extracting features using MS_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:26<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [2/5]Finished Extracting features using MS_Clap ***\n",
      "\n",
      "*** [3/5]Extracting features using Laion_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:05<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [3/5]Finished Extracting features using Laion_Clap ***\n",
      "\n",
      "*** [4/5]Extracting features using MGA_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:15<00:00, 23.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [4/5]Finished Extracting features using MGA_Clap ***\n",
      "\n",
      "*** [5/5]Extracting features using Whisper... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [10:59<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [5/5]Finished Extracting features using Whisper ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------ Val set ------\")\n",
    "if 'X_dict_val' not in globals() and 'y_dict_val' not in globals():\n",
    "    X_dict_val, y_dict_val, param = get_all_features_in_dict(val_loader, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730f867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9bea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SVR A ---\n",
      "Preprocessing...\n",
      "Training SVR...\n",
      "Predicting on Train set...\n",
      "\t {'SRCC': 0.9275749329754529, 'LCC': 0.9295733184259705, 'KTAU': 0.7927382587553667, 'MSE': 0.8959294885956849, 'N': 7500}\n",
      "Predicting on Val set...\n",
      "\t {'SRCC': 0.6571085882541974, 'LCC': 0.6765082897111823, 'KTAU': 0.4754672570356058, 'MSE': 3.112910980514286, 'N': 3000}\n",
      "Preprocessors and SVR model saved for ensemble set: ./outputs/version_config_submission4/A/ \n",
      "\n",
      "\n",
      "--- SVR B ---\n",
      "Preprocessing...\n",
      "Training SVR...\n",
      "Predicting on Train set...\n",
      "\t {'SRCC': 0.9364892531730183, 'LCC': 0.9207503439284456, 'KTAU': 0.8277503727054965, 'MSE': 1.0161497807248185, 'N': 7500}\n",
      "Predicting on Val set...\n",
      "\t {'SRCC': 0.5789392559840857, 'LCC': 0.5861761963179108, 'KTAU': 0.4134016401376451, 'MSE': 3.7540573304077114, 'N': 3000}\n",
      "Preprocessors and SVR model saved for ensemble set: ./outputs/version_config_submission4/B/ \n",
      "\n",
      "\n",
      "Ensemble: Prediction = W_A*SVR_A + W_B*SVR_B\n",
      "Predicting on Train set...\n",
      "\t {'SRCC': 0.944291999198004, 'LCC': 0.9388169515983688, 'KTAU': 0.8201781170434792, 'MSE': 0.8438454227729538, 'N': 7500}\n",
      "\n",
      "Predicting on Val set...\n",
      "\t {'SRCC': 0.6623105449747249, 'LCC': 0.6783693180420468, 'KTAU': 0.48064720787525883, 'MSE': 3.1173260667728213, 'N': 3000}\n",
      "\n",
      "Total Parameter Count: 2065193549\n"
     ]
    }
   ],
   "source": [
    "# Fit SVR A and B\n",
    "SVR_A_input_param = cfg['SVR']['A']['input_param']\n",
    "y_pred_train_denorm_A, y_pred_val_denorm_A, param = Fit_SVR_A(X_dict, X_dict_val, y_dict, y_dict_val, SVR_A_input_param, param, cfg)\n",
    "\n",
    "SVR_B_input_param = cfg['SVR']['B']['input_param']\n",
    "y_pred_train_denorm_B, y_pred_val_denorm_B, param = Fit_SVR_B(X_dict, X_dict_val, y_dict, y_dict_val,  SVR_B_input_param, param, cfg)\n",
    "\n",
    "# Optimize Weights for Ensemble\n",
    "y = GetLabels(y_dict)\n",
    "y_val = GetLabels(y_dict_val)\n",
    "y_denorm = y*5 + 5\n",
    "y_denorm_val = y_val*5 + 5\n",
    "def min_func(K):\n",
    "    y_pred_train = K[0]*y_pred_train_denorm_A + K[1]*y_pred_train_denorm_B\n",
    "    return RMSE(y_denorm, y_pred_train)\n",
    "res = minimize(min_func, [1/2]*2, method='TNC', tol=1e-6)\n",
    "W = res.x\n",
    "cfg['W'] = W.tolist()\n",
    "\n",
    "# Final Train and Validation Results\n",
    "print('\\nEnsemble: Prediction = W_A*SVR_A + W_B*SVR_B')\n",
    "print('Predicting on Train set...')\n",
    "y_pred_train = W[0]*y_pred_train_denorm_A + W[1]*y_pred_train_denorm_B\n",
    "y_pred_train_clipped = np.clip(y_pred_train, 0, 10)\n",
    "results = evaluate_all(y_pred_train_clipped, y_denorm)\n",
    "print('\\t', results)\n",
    "\n",
    "print('\\nPredicting on Val set...')\n",
    "y_pred_val = W[0]*y_pred_val_denorm_A + W[1]*y_pred_val_denorm_B\n",
    "y_pred_val_clipped = np.clip(y_pred_val, 0, 10)\n",
    "results_val = evaluate_all(y_pred_val_clipped, y_denorm_val)\n",
    "print('\\t', results_val)\n",
    "\n",
    "Param_count(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2d7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config file for trained model\n",
    "config_filepath_filename = os.path.join(cfg['output_dir'] + '/version_' + cfg['config_filename'].split('.')[0], 'config.json')\n",
    "with open(config_filepath_filename, \"w\") as json_file:\n",
    "    json.dump(cfg, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b95b71",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e75a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9ec560",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_subdir_name = 'version_config_submission4'\n",
    "config_filepath_filename = os.path.join('./outputs', chkpt_subdir_name, 'config.json')\n",
    "cfg = utils.load_config(config_filepath_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "116993a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_SVR(dataset_key, X_comb_test, Normalizer_, StandardScaler_, SVR_, cfg):\n",
    "    # Preprocessing\n",
    "    print('Preprocessing...')\n",
    "    X_scaled_comb_test = Normalizer_.transform(X_comb_test)\n",
    "    X_scaled_comb_test = StandardScaler_.transform(X_scaled_comb_test)\n",
    "\n",
    "    # SVR_A\n",
    "    print(f'Predicting on {dataset_key} set...')\n",
    "    y_pred_test = SVR_.predict(X_scaled_comb_test)\n",
    "    y_pred_test_denorm = y_pred_test*5 + 5\n",
    "    \n",
    "    return y_pred_test_denorm\n",
    "\n",
    "\n",
    "def Predict_SVR_A(dataset_key, X_dict_test, cfg): \n",
    "        Ensemble_set = 'A'\n",
    "        print(f'--- SVR {Ensemble_set} ---')\n",
    "        \n",
    "        X_comb_test_A = np.concatenate((X_dict_test['M2D_Clap']['AudioFeatures'], X_dict_test['M2D_Clap']['TextFeatures'], X_dict_test['M2D_Clap']['Cosine_Sim'], \n",
    "                                    X_dict_test['M2D_Clap']['Cosine_Ang'], X_dict_test['M2D_Clap']['L2'], X_dict_test['M2D_Clap']['L1'],\n",
    "\n",
    "                                    X_dict_test['MS_Clap']['AudioFeatures'], X_dict_test['MS_Clap']['TextFeatures'], X_dict_test['MS_Clap']['Cosine_Sim'], \n",
    "                                    X_dict_test['MS_Clap']['Cosine_Ang'], X_dict_test['MS_Clap']['L2'], X_dict_test['MS_Clap']['L1'],\n",
    "                                    \n",
    "                                    X_dict_test['MGA_Clap']['AudioFeatures'], X_dict_test['MGA_Clap']['TextFeatures'], X_dict_test['MGA_Clap']['Cosine_Sim'], \n",
    "                                    X_dict_test['MGA_Clap']['Cosine_Ang'], X_dict_test['MGA_Clap']['L2'], X_dict_test['MGA_Clap']['L1'],), axis=1)\n",
    "        \n",
    "        Normalizer_name = cfg['preprocessor']['A']['Normalizer']\n",
    "        StandardScaler_name = cfg['preprocessor']['A']['StandardScaler']\n",
    "        SVR_name = cfg['SVR']['A']['name']\n",
    "        Ensemble_set = 'A'\n",
    "        Normalizer_A, StandardScaler_A, SVR_A = utils.Load_Preprocessor_and_SVR(Normalizer_name, StandardScaler_name, SVR_name, Ensemble_set, cfg)\n",
    "        y_pred_test_denorm_A = Predict_SVR(dataset_key, X_comb_test_A, Normalizer_A, StandardScaler_A, SVR_A, cfg)\n",
    "\n",
    "        return y_pred_test_denorm_A\n",
    "\n",
    "\n",
    "def Predict_SVR_B(dataset_key, X_dict_test, cfg): \n",
    "        Ensemble_set = 'B'\n",
    "        print(f'--- SVR {Ensemble_set} ---')\n",
    "        \n",
    "        X_comb_test_B = np.concatenate((X_dict_test['Laion_Clap']['AudioFeatures'], X_dict_test['Laion_Clap']['TextFeatures'], X_dict_test['Laion_Clap']['L1'],\n",
    "                                   X_dict_test['Whisper']['AudioFeatures'], X_dict_test['Whisper']['TextFeatures'],), axis=1)\n",
    "         \n",
    "        Normalizer_name = cfg['preprocessor']['B']['Normalizer']\n",
    "        StandardScaler_name = cfg['preprocessor']['B']['StandardScaler']\n",
    "        SVR_name = cfg['SVR']['B']['name']\n",
    "        Ensemble_set = 'B'\n",
    "        Normalizer_B, StandardScaler_B, SVR_B = utils.Load_Preprocessor_and_SVR(Normalizer_name, StandardScaler_name, SVR_name, Ensemble_set, cfg)\n",
    "        y_pred_test_denorm_B = Predict_SVR(dataset_key, X_comb_test_B, Normalizer_B, StandardScaler_B, SVR_B, cfg)\n",
    "\n",
    "        return y_pred_test_denorm_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74072e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Test set ------\n",
      "*** [1/5]Extracting features using M2D_Clap... ***\n",
      " using 166 parameters from m2d/m2d_clap_vit_base-80x1001p16x16p16kpBpTI-2025/checkpoint-30.pth\n",
      " (included audio_proj params: ['audio_proj.sem_token', 'audio_proj.sem_blocks.0.norm1.weight', 'audio_proj.sem_blocks.0.norm1.bias', 'audio_proj.sem_blocks.0.attn.qkv.weight', 'audio_proj.sem_blocks.0.attn.qkv.bias']\n",
      " (included text_proj params: []\n",
      " (dropped: [] )\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " using model.text_encoder from ./m2d/m2d_clap_vit_base-80x1001p16x16p16kpBpTI-2025/checkpoint-30.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:29<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [1/5]Finished Extracting features using M2D_Clap ***\n",
      "\n",
      "*** [2/5]Extracting features using MS_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:26<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [2/5]Finished Extracting features using MS_Clap ***\n",
      "\n",
      "*** [3/5]Extracting features using Laion_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:04<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [3/5]Finished Extracting features using Laion_Clap ***\n",
      "\n",
      "*** [4/5]Extracting features using MGA_Clap... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:14<00:00, 25.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [4/5]Finished Extracting features using MGA_Clap ***\n",
      "\n",
      "*** [5/5]Extracting features using Whisper... ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [10:58<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** [5/5]Finished Extracting features using Whisper ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n------ Test set ------\")\n",
    "if 'X_dict_test' not in globals() and 'y_dict_test' not in globals():\n",
    "    X_dict_test, _, param = get_all_features_in_dict(test_loader, cfg, test_data=True)\n",
    "\n",
    "# Clear GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f54d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Inference(dataset_key, loader, X_dict_inf, cfg):\n",
    "    y_pred_inf_denorm_A = Predict_SVR_A(dataset_key, X_dict_inf, cfg)\n",
    "    y_pred_inf_denorm_B = Predict_SVR_B(dataset_key, X_dict_inf, cfg)\n",
    "\n",
    "    print('\\nEnsemble: Prediction = W_A*SVR_A + W_B*SVR_B')\n",
    "    print(f'Predicting on {dataset_key} set...\\n')\n",
    "    y_pred_inf = cfg['W'][0]*y_pred_inf_denorm_A + cfg['W'][1]*y_pred_inf_denorm_B\n",
    "    y_pred_inf_clipped = np.clip(y_pred_inf, 0, 10)\n",
    "\n",
    "    utils.Save_Inference(y_pred_inf_clipped, loader, cfg, dataset_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "780753a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SVR A ---\n",
      "Preprocessing...\n",
      "Predicting on validation set...\n",
      "--- SVR B ---\n",
      "Preprocessing...\n",
      "Predicting on validation set...\n",
      "\n",
      "Ensemble: Prediction = W_A*SVR_A + W_B*SVR_B\n",
      "Predicting on validation set...\n",
      "\n",
      "Warning: make sure data_loader was set to *shuffle=False* while training SVRs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:03<00:00, 117.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file is saved \n",
      "Path: ./outputs/version_config_submission4 \n",
      "filename: inference_result_for_validation.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference on Validation set\n",
    "Predict_Inference('validation', val_loader, X_dict_val, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "212c8389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation will be conducted based on the following two files:\n",
      "\t- /home/u5049807/Ensemble_SVR/outputs/version_config_submission4/inference_result_for_validation.csv\n",
      "\t- /home/u5049807/Ensemble_SVR/datasets/XACLE_dataset/meta_data/validation_average.csv\n",
      "The result will be saved to: /home/u5049807/Ensemble_SVR/outputs/version_config_submission4/evaluation_result.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Evaluation Scores: SRCC, LCC, KTAU, MSE\n",
    "# %run evaluate.py <inference_csv_path> <ground_truth_csv_path> <save_results_dir>\n",
    "%run evaluate.py outputs/version_config_submission4/inference_result_for_validation.csv datasets/XACLE_dataset/meta_data/validation_average.csv outputs/version_config_submission4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba9cad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SVR A ---\n",
      "Preprocessing...\n",
      "Predicting on test set...\n",
      "--- SVR B ---\n",
      "Preprocessing...\n",
      "Predicting on test set...\n",
      "\n",
      "Ensemble: Prediction = W_A*SVR_A + W_B*SVR_B\n",
      "Predicting on test set...\n",
      "\n",
      "Warning: make sure data_loader was set to *shuffle=False* while training SVRs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:02<00:00, 163.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file is saved \n",
      "Path: ./outputs/version_config_submission4 \n",
      "filename: inference_result_for_test.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference on Test set\n",
    "Predict_Inference('test', test_loader, X_dict_test, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c8e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xacle_exp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
